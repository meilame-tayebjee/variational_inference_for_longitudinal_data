{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src/')\n",
    "sys.path.append('scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch\n",
    "import logging\n",
    "from pythae.models import LVAE_IAF, LVAE_IAF_Config, AutoModel\n",
    "from pythae.trainers import BaseTrainerConfig, BaseTrainer\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import Encoder_ColorMNIST, Encoder_Chairs, Decoder_ColorMNIST, Decoder_Chairs, Encoder_Faces, Decoder_Faces, My_Dataset, My_MaskedDataset, make_batched_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANIFEST.in       experiments.ipynb pyproject.toml    setup.cfg\n",
      "README.md         \u001b[34mmy_data\u001b[m\u001b[m           requirements.txt  setup.py\n",
      "\u001b[34mdata_folders\u001b[m\u001b[m      \u001b[34mplots\u001b[m\u001b[m             \u001b[34mscripts\u001b[m\u001b[m           \u001b[34msrc\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(os.path.join('my_data/sprites/Sprites_train.pt'))[:-1000]\n",
    "eval_data = torch.load(os.path.join('my_data/sprites/Sprites_train.pt'), map_location=\"cpu\")[-1000:]\n",
    "test_data = torch.load(os.path.join('my_data/sprites/Sprites_test.pt'), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (3, 64, 64)\n",
    "latent_dim = 16\n",
    "beta = 1\n",
    "n_hidden_in_made = 3\n",
    "n_made_blocks = 2\n",
    "warmup = 10\n",
    "context_dim = None\n",
    "prior = 'vamp'\n",
    "posterior = 'iaf'\n",
    "vamp_number_components= 500\n",
    "linear_scheduling_steps = 10\n",
    "num_epochs = 400\n",
    "batch_size = 64\n",
    "learning_rate=  1e-3 \n",
    "steps_saving = None\n",
    "steps_predict = 100\n",
    "shuffle_data = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LVAE_IAF_Config(\n",
    "    input_dim=input_dim,\n",
    "    n_obs_per_ind=train_data.shape[1],\n",
    "    latent_dim=latent_dim,\n",
    "    beta=beta,\n",
    "    n_hidden_in_made=n_hidden_in_made,\n",
    "    n_made_blocks=n_made_blocks,\n",
    "    warmup=warmup,\n",
    "    context_dim=context_dim,\n",
    "    prior=prior,\n",
    "    posterior=posterior,\n",
    "    vamp_number_components=vamp_number_components,\n",
    "    linear_scheduling_steps=linear_scheduling_steps\n",
    ")\n",
    "\n",
    "training_config = BaseTrainerConfig(\n",
    "        num_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        steps_saving=steps_saving,\n",
    "        steps_predict=steps_predict,\n",
    "        shuffle=shuffle_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder_Chairs(config)\n",
    "decoder = Decoder_Chairs(config)\n",
    "\n",
    "model = LVAE_IAF(config, encoder, decoder).to('cpu')\n",
    "\n",
    "### Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=training_config.learning_rate, eps=1e-4)\n",
    "\n",
    "### Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=[50, 100, 125, 150],\n",
    "    gamma=0.5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_mask = torch.ones(train_data.shape[:2], requires_grad=False).type(torch.bool)\n",
    "eval_seq_mask = torch.ones(eval_data.shape[:2], requires_grad=False).type(torch.bool)\n",
    "test_seq_mask = torch.ones(test_data.shape[:2], requires_grad=False).type(torch.bool)\n",
    "train_pix_mask = torch.ones_like(train_data, requires_grad=False).type(torch.bool)\n",
    "eval_pix_mask = torch.ones_like(eval_data, requires_grad=False).type(torch.bool)\n",
    "test_pix_mask = torch.ones_like(test_data, requires_grad=False).type(torch.bool)\n",
    "\n",
    "train_dataset = My_MaskedDataset(train_data, train_seq_mask, train_pix_mask)\n",
    "eval_dataset = My_MaskedDataset(eval_data, eval_seq_mask, eval_pix_mask)\n",
    "test_dataset = My_MaskedDataset(test_data, test_seq_mask, test_pix_mask)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created dummy_output_dir folder since did not exist.\n",
      "\n",
      "Model passed sanity check !\n",
      "\n",
      "Created dummy_output_dir/LVAE_IAF_training_2024-04-30_13-28-35. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Successfully launched training !\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421aa2e968d4a3e9175f5cd2e1a2ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training of epoch 1/400:   0%|          | 0/125 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = BaseTrainer(\n",
    "            model=model,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=eval_dataset,\n",
    "            training_config=training_config,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "        )\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
